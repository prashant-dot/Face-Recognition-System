{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FRS using deep learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNNYM/CiYwu0v/9Toao1lqK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prashant-dot/Face-Recognition-System/blob/main/FRS_using_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiwIQzPhywwv"
      },
      "source": [
        "import cv2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "Zl_rg7e0y7ob",
        "outputId": "eeb059c8-9a62-4be4-804b-8eb29bc14ce2"
      },
      "source": [
        "def generate_dataset():\n",
        "    face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
        "    def face_cropped(img):\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
        "        \n",
        "        if faces is ():\n",
        "            return None\n",
        "        for (x,y,w,h) in faces:\n",
        "            cropped_face = img[y:y+h,x:x+w]\n",
        "        return cropped_face\n",
        "    \n",
        "    cap = cv2.VideoCapture(0)\n",
        "    img_id = 0\n",
        "    if not cap.isOpened():\n",
        "        raise IOError(\"Cannot open webcam\")\n",
        "    cv2.imshow('Input', frame)\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        print(frame)\n",
        "        if face_cropped(frame) is not None:\n",
        "            img_id+=1\n",
        "            face = cv2.resize(face_cropped(frame), (200,200))\n",
        "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
        "            file_name_path = \"data/\"+\"Prashant.\"+str(img_id)+\".jpg\"\n",
        "            #file_name_path = \"Images for visualization/\"+str(img_id)+'.jpg'\n",
        "            cv2.imwrite(file_name_path, face)\n",
        "            cv2.putText(face, str(img_id), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2 )\n",
        "            \n",
        "            cv2.imshow(\"Cropped_Face\", face)\n",
        "            if cv2.waitKey(1)==13 or int(img_id)==20:\n",
        "                break\n",
        "                \n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    print(\"Collecting samples is completed !!!\")\n",
        "generate_dataset()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'def generate_dataset():\\n    face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\\n    def face_cropped(img):\\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\\n        faces = face_classifier.detectMultiScale(gray, 1.3, 5)\\n        \\n        if faces is ():\\n            return None\\n        for (x,y,w,h) in faces:\\n            cropped_face = img[y:y+h,x:x+w]\\n        return cropped_face\\n    \\n    cap = cv2.VideoCapture(0)\\n    img_id = 0\\n    if not cap.isOpened():\\n        raise IOError(\"Cannot open webcam\")\\n    cv2.imshow(\\'Input\\', frame)\\n    while True:\\n        ret, frame = cap.read()\\n        print(frame)\\n        if face_cropped(frame) is not None:\\n            img_id+=1\\n            face = cv2.resize(face_cropped(frame), (200,200))\\n            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\\n            file_name_path = \"data/\"+\"Prashant.\"+str(img_id)+\".jpg\"\\n            #file_name_path = \"Images for visualization/\"+str(img_id)+\\'.jpg\\'\\n            cv2.imwrite(file_name_path, face)\\n            cv2.putText(face, str(img_id), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2 )\\n            \\n            cv2.imshow(\"Cropped_Face\", face)\\n            if cv2.waitKey(1)==13 or int(img_id)==20:\\n                break\\n                \\n    cap.release()\\n    cv2.destroyAllWindows()\\n    print(\"Collecting samples is completed !!!\")\\ngenerate_dataset()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4iRaDww30xk"
      },
      "source": [
        "import numpy as np # pip install numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_dp_was4hUh"
      },
      "source": [
        "def my_label(image_name):\n",
        "    name = image_name.split('.')[-3] \n",
        "    if name==\"Prashant\":\n",
        "        return np.array([1,0,0])\n",
        "    elif name==\"Mukesh\":\n",
        "        return np.array([0,1,0])\n",
        "    elif name==\"Peter\":\n",
        "        return np.array([0,0,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxOczbaY51uq"
      },
      "source": [
        "import os\n",
        "from random import shuffle\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wR54c6Z54rq"
      },
      "source": [
        "def my_data():\n",
        "    data = []\n",
        "    for img in tqdm(os.listdir(\"data\")):\n",
        "        path=os.path.join(\"data\",img)\n",
        "        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        img_data = cv2.resize(img_data, (50,50))\n",
        "        data.append([np.array(img_data), my_label(img)])\n",
        "    shuffle(data)  \n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8v_ZWOp58pf"
      },
      "source": [
        "data = my_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PL9iVeBz59gv"
      },
      "source": [
        "train = data[:2400]  \n",
        "test = data[2400:]\n",
        "X_train = np.array([i[0] for i in train]).reshape(-1,50,50,1)\n",
        "print(X_train.shape)\n",
        "y_train = [i[1] for i in train]\n",
        "X_test = np.array([i[0] for i in test]).reshape(-1,50,50,1)\n",
        "print(X_test.shape)\n",
        "y_test = [i[1] for i in test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8J0jvaP6Adn"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tflearn\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9ZcVTUn6JXf"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "convnet = input_data(shape=[50,50,1])\n",
        "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
        "# 32 filters and stride=5 so that the filter will move 5 pixel or unit at a time\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "\n",
        "convnet = fully_connected(convnet, 1024, activation='relu')\n",
        "convnet = dropout(convnet, 0.8)\n",
        "convnet = fully_connected(convnet, 3, activation='softmax')\n",
        "convnet = regression(convnet, optimizer='adam', learning_rate = 0.001, loss='categorical_crossentropy')\n",
        "model = tflearn.DNN(convnet, tensorboard_verbose=1)\n",
        "model.fit(X_train, y_train, n_epoch=12, validation_set=(X_test, y_test), show_metric = True, run_id=\"FRS\" )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvfgZ5Md6jKd"
      },
      "source": [
        "def data_for_visualization():\n",
        "    Vdata = []\n",
        "    for img in tqdm(os.listdir(\"Images for visualization\")):\n",
        "        path = os.path.join(\"Images for visualization\", img)\n",
        "        img_num = img.split('.')[0] \n",
        "        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        img_data = cv2.resize(img_data, (50,50))\n",
        "        Vdata.append([np.array(img_data), img_num])\n",
        "    shuffle(Vdata)\n",
        "    return Vdata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBtFqtVI6p7g"
      },
      "source": [
        "Vdata = data_for_visualization()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1hRHVGE6rFB"
      },
      "source": [
        "import matplotlib.pyplot as plt   # pip install matplotlib\n",
        "\n",
        "fig = plt.figure(figsize=(20,20))\n",
        "for num, data in enumerate(Vdata[:20]):\n",
        "    img_data = data[0]\n",
        "    y = fig.add_subplot(5,5, num+1)\n",
        "    image = img_data\n",
        "    data = img_data.reshape(50,50,1)\n",
        "    model_out = model.predict([data])[0]\n",
        "    \n",
        "    if np.argmax(model_out) == 0:\n",
        "        my_label = 'Prashant'\n",
        "    elif np.argmax(model_out) == 1:\n",
        "        my_label = 'Manish'\n",
        "    else:\n",
        "        my_label = 'Paul'\n",
        "        \n",
        "    y.imshow(image, cmap='gray')\n",
        "    plt.title(my_label)\n",
        "    \n",
        "    y.axes.get_xaxis().set_visible(False)\n",
        "    y.axes.get_yaxis().set_visible(False)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2_qHS3l6318"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}